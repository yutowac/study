# Gemmaとは
Gemini モデルの作成に使用されたものと同じ研究とテクノロジーに基づいて構築された、軽量で最先端のオープンモデルのファミリー

[Hugging Face](https://huggingface.co/google/gemma-2-2b-jpn-it)

## ファミリーモデル
- [PaliGemma](https://developers.googleblog.com/ja/gemma-explained-paligemma-architecture/)
- [RecurrentGemma](https://developers.googleblog.com/ja/gemma-explained-recurrentgemma-architecture/)
- [DataGemma](https://ai.google.dev/gemma/docs/datagemma?hl=ja)
- [CodeGemma](https://ai.google.dev/gemma/docs/codegemma)


## Geminiとの違い
[WikiPedia](https://ja.wikipedia.org/wiki/Gemini_(%E3%83%81%E3%83%A3%E3%83%83%E3%83%88%E3%83%9C%E3%83%83%E3%83%88))
[Medium](https://medium.com/pythoneers/exploring-gemma-google-open-source-ai-model-812e71b539c0)

# Fine-Tuningとは
## 転移学習とFine-Tuning
[説明](https://chefyushima.com/df_pt-ft-tl/3325/#google_vignette)

# sample
[Github](https://colab.research.google.com/github/bebechien/gemma/blob/main/How_to_Fine_tuning_Gemma_Random_Japanese_Movie_Titles.ipynb#scrollTo=i1PHqD-ZY4-c)
